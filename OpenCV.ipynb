{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basics of OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read image and store it in variable img\n",
    "# The image is stored as numpy array of 3-D matrix for colored images(R,G,B) and 2-D matrix for grayscale images.\n",
    "# The second parameter is 1-colored image, 0-grayscale, -1- unchanged image\n",
    "# However if left blank 1 that is colored image is default value.\n",
    "img = cv2.imread(\"C:\\\\Users\\ASUS\\\\Pictures\\\\Screenshots\\\\check.png\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(830, 812, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The image is a colored image of 830 pixels of rows, 812 pixels of columns and 3 channels(RGB).\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying image, the following lines of code need to be used to display image\n",
    "# waitkey if left blank or 0 expects keyboard input to destroy the image, else parameter is expected in milliseconds \n",
    "# destroyAllWindows is required to remove image after being displayed\n",
    "# The below 3 lines of code always need to be written together\n",
    "cv2.imshow(\"new image\",resized)\n",
    "cv2.waitKey(2000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 200, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resizing image using cv2.resize, the second parameter takes (columns, rows) which is opposite to numpy array\n",
    "resized = cv2.resize(img,(200,400))\n",
    "# numpy array\n",
    "resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(415, 406, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To reduce image size by half, note the column and row parameter is opposite to numpy array's shape attribute\n",
    "resized = cv2.resize(img,(int(img.shape[1]/2),int(img.shape[0]/2)))\n",
    "# numpy array\n",
    "resized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face Detection using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cascade Classifier contains the features of the face, here the xml files contains the features of a frontal face\n",
    "# Various haar cascades are available on the internet for eye, upper body, etc. \n",
    "# The Haar Cascade is trained by superimposing the positive image over a set of negative images. \n",
    "# Other option is LBP which is faster and a better choice for embedded systems as it performs calculations in intergers\n",
    "# as opposed to haar which performs calulations in float.\n",
    "# --->https://github.com/opencv/opencv/tree/master/data/haarcascades\n",
    "face_cascade = cv2.CascadeClassifier(\"C:\\\\Users\\\\ASUS\\\\opencv-files\\\\haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The face is loaded and stored as numpy.ndarray \n",
    "# The face is loaded as colored image as 1 is considered default value.\n",
    "img2 = cv2.imread(\"C:\\\\Users\\\\ASUS\\\\Pictures\\\\Screenshots\\\\photo.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The image is converted to grayscale \n",
    "gray_img = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting coordinates of face using detectMultiScale function\n",
    "faces = face_cascade.detectMultiScale(gray_img, scaleFactor=1.05, minNeighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[144 130 259 259]]\n"
     ]
    }
   ],
   "source": [
    "print(type(faces))\n",
    "# prints coordinates of face\n",
    "print(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding rectangular box around the face\n",
    "for x,y,w,h in faces:\n",
    "    img2 = cv2.rectangle(img2, (x,y), (x+w,y+h), (0,255,0), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying face on screen to the user\n",
    "cv2.imshow(\"gray\",img2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturing Video using OpenCV and inbuilt webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Create the videoCapture object, 0 tells the computer to use built-in camera. 1 will be for external camera.\n",
    "# Instead of an integer, path to a video file can be provided as parameter.\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "# Check is boolean variable and tells if it has captured an image\n",
    "# frame is ndarray which represents the image\n",
    "check, frame = video.read()\n",
    "\n",
    "print(check)\n",
    "#print(frame)\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying captured image\n",
    "cv2.imshow(\"new image\",frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "video = cv2.VideoCapture(0)\n",
    "a=1\n",
    "while True:\n",
    "    a=a+1\n",
    "    check, frame = video.read()\n",
    "    print(check)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow(\"capture\", gray)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key==ord('q'):\n",
    "        break\n",
    "\n",
    "print(a)\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
